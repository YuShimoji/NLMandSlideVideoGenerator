"""
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
YouTubeå‹•ç”»ç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ã€æ¦‚è¦ã€ã‚¿ã‚°ã‚’è‡ªå‹•ç”Ÿæˆ
"""
import asyncio
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import re
from collections import Counter
from datetime import datetime

from core.utils.logger import logger
from config.settings import settings
from notebook_lm.transcript_processor import TranscriptInfo, TranscriptSegment

@dataclass
class VideoMetadata:
    """å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    title: str
    description: str
    tags: List[str]
    category_id: str
    thumbnail_suggestions: Optional[List[str]] = None
    language: Optional[str] = None
    privacy_status: Optional[str] = None

class MetadataGenerator:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, template_dir: Optional[Path] = None):
        self.youtube_settings = settings.YOUTUBE_SETTINGS
        self.max_title_length = self.youtube_settings["max_title_length"]
        self.max_description_length = self.youtube_settings["max_description_length"]
        self.max_tags_length = self.youtube_settings["max_tags_length"]
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.template_dir = template_dir or settings.TEMPLATES_DIR / "metadata"
        self.template_dir.mkdir(exist_ok=True)
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
        self.templates = self._load_templates()
    
    def _load_templates(self) -> Dict[str, Dict[str, Any]]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        templates = {}
        
        if self.template_dir.exists():
            for template_file in self.template_dir.glob("*.json"):
                try:
                    with open(template_file, 'r', encoding='utf-8') as f:
                        template_data = json.load(f)
                        template_name = template_file.stem
                        templates[template_name] = template_data
                        logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿: {template_name}")
                except Exception as e:
                    logger.warning(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {template_file}: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        templates.setdefault('default', {
            'title_template': '{topic} - {key_points}',
            'description_template': 'ã“ã®å‹•ç”»ã§ã¯{topic}ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚\n\n{toc}\n\n{hashtags}',
            'tags_template': ['{topic}', 'è§£èª¬', 'ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«'],
            'category_id': self.youtube_settings['category_id'],
            'language': self.youtube_settings['default_language']
        })
        
        return templates
    
    async def generate_metadata(self, transcript: TranscriptInfo, template_name: str = "default") -> Dict[str, Any]:
        """
        å°æœ¬ã‹ã‚‰YouTubeç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            template_name: ä½¿ç”¨ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
            
        Returns:
            Dict[str, Any]: ç”Ÿæˆã•ã‚ŒãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"YouTubeãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹ (ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template_name})")
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ¤œè¨¼
        if template_name not in self.templates:
            logger.warning(f"ä¸æ˜ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_name}'ã€default ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            template_name = "default"
        
        template = self.templates[template_name]
        logger.info(f"é©ç”¨ã™ã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template}")
        
        try:
            # Step 1: ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
            title = self._generate_title_from_template(transcript, template)
            
            # Step 2: æ¦‚è¦æ¬„ç”Ÿæˆ
            description = self._generate_description_from_template(transcript, template)
            
            # Step 3: ã‚¿ã‚°ç”Ÿæˆ
            tags = self._generate_tags_from_template(transcript, template)
            
            # Step 4: ã‚µãƒ ãƒã‚¤ãƒ«ææ¡ˆç”Ÿæˆ
            thumbnail_suggestions = self._generate_thumbnail_suggestions(transcript)
            
            metadata = {
                "title": title,
                "description": description,
                "tags": tags,
                "category_id": self.youtube_settings["category_id"],
                "thumbnail_suggestions": thumbnail_suggestions
            }
            # æ—¢å®šã®è¨€èªã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¨­å®šã‚’ä»˜ä¸ï¼ˆå¾Œã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
            metadata.setdefault("language", self.youtube_settings.get("default_language", "ja"))
            metadata.setdefault("privacy_status", self.youtube_settings.get("privacy_status", "private"))
            
            logger.success("YouTubeãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†")
            return metadata
            
        except Exception as e:
            logger.error(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _generate_title(self, transcript: TranscriptInfo) -> str:
        """
        å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
        """
        # æ—¢å­˜ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã«
        base_title = transcript.title
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self._extract_main_keywords(transcript)
        
        # SEOæœ€é©åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
        if keywords:
            main_keyword = keywords[0]
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
            title_patterns = [
                f"ã€è§£èª¬ã€‘{main_keyword}ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¾ã™",
                f"{main_keyword}ã®åŸºæœ¬ã‹ã‚‰å¿œç”¨ã¾ã§å®Œå…¨è§£èª¬",
                f"ä»Šã•ã‚‰èã‘ãªã„{main_keyword}ã®å…¨ã¦",
                f"{main_keyword}ã‚’åˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã€åˆå¿ƒè€…å‘ã‘ã€‘",
                f"ã€æœ€æ–°æƒ…å ±ã€‘{main_keyword}ã®å‹•å‘ã¨ä»Šå¾Œã®å±•æœ›"
            ]
            
            # æœ€ã‚‚é©åˆ‡ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
            for pattern in title_patterns:
                if len(pattern) <= self.max_title_length:
                    return pattern
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’èª¿æ•´
        if len(base_title) <= self.max_title_length:
            return base_title
        else:
            return base_title[:self.max_title_length-3] + "..."
    
    def _generate_description(self, transcript: TranscriptInfo) -> str:
        """
        å‹•ç”»æ¦‚è¦æ¬„ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸæ¦‚è¦æ¬„
        """
        description_parts = []
        
        # 1. å‹•ç”»æ¦‚è¦
        summary = self._generate_video_summary(transcript)
        description_parts.append(f"ã€å‹•ç”»æ¦‚è¦ã€‘\n{summary}\n")
        
        # 2. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãç›®æ¬¡
        chapters = self._generate_chapters(transcript)
        if chapters:
            description_parts.append("ã€ç›®æ¬¡ã€‘")
            description_parts.extend(chapters)
            description_parts.append("")
        
        # 3. é‡è¦ãƒã‚¤ãƒ³ãƒˆ
        key_points = self._extract_key_points_for_description(transcript)
        if key_points:
            description_parts.append("ã€é‡è¦ãƒã‚¤ãƒ³ãƒˆã€‘")
            description_parts.extend([f"âœ“ {point}" for point in key_points])
            description_parts.append("")
        
        # 4. é–¢é€£æƒ…å ±ãƒ»ã‚½ãƒ¼ã‚¹
        sources = self._extract_source_information(transcript)
        if sources:
            description_parts.append("ã€å‚è€ƒæƒ…å ±ã€‘")
            description_parts.extend(sources)
            description_parts.append("")
        
        # 5. ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ãƒ»ãŠæ±ºã¾ã‚Šã®æ–‡è¨€
        description_parts.extend([
            "ã€ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ã€‘",
            "ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ã¯ã€æœ€æ–°ã®æŠ€è¡“å‹•å‘ã‚„è§£èª¬å‹•ç”»ã‚’å®šæœŸçš„ã«é…ä¿¡ã—ã¦ã„ã¾ã™ã€‚",
            "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ãƒ»é«˜è©•ä¾¡ã‚’ãŠé¡˜ã„ã—ã¾ã™ï¼",
            "",
            "ã€ãŠå•ã„åˆã‚ã›ã€‘",
            "ã”è³ªå•ã‚„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚ã‚Šã¾ã—ãŸã‚‰ã€ã‚³ãƒ¡ãƒ³ãƒˆæ¬„ã«ãŠæ›¸ããã ã•ã„ã€‚",
            "",
            f"#è§£èª¬å‹•ç”» #{self._get_main_hashtag(transcript)}"
        ])
        
        # æ–‡å­—æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        full_description = "\n".join(description_parts)
        if len(full_description) > self.max_description_length:
            # é•·ã™ãã‚‹å ´åˆã¯è¦ç´„ç‰ˆã‚’ä½œæˆ
            return self._create_shortened_description(transcript, summary, chapters[:5])
        
        return full_description
    
    def _generate_video_summary(self, transcript: TranscriptInfo) -> str:
        """
        å‹•ç”»ã®è¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            str: å‹•ç”»è¦ç´„
        """
        # æœ€åˆã¨æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰è¦ç´„ã‚’ä½œæˆ
        if not transcript.segments:
            return "ã“ã®å‹•ç”»ã§ã¯é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚"
        
        first_segment = transcript.segments[0]
        
        # æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä¸»è¦ãªå†…å®¹ã‚’æŠ½å‡º
        summary_base = first_segment.text[:200]
        
        # å…¨ä½“ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’çµ±åˆ
        all_key_points = []
        for segment in transcript.segments:
            all_key_points.extend(segment.key_points)
        
        # é »å‡ºã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®š
        point_counts = Counter(all_key_points)
        top_points = [point for point, count in point_counts.most_common(3)]
        
        if top_points:
            summary = f"{summary_base}ä¸»ã«{', '.join(top_points)}ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚"
        else:
            summary = summary_base
        
        return summary[:300] + "..." if len(summary) > 300 else summary
    
    def _generate_chapters(self, transcript: TranscriptInfo) -> List[str]:
        """
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒãƒ£ãƒ—ã‚¿ãƒ¼ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ãƒãƒ£ãƒ—ã‚¿ãƒ¼ä¸€è¦§
        """
        chapters = []
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        chapter_groups = self._group_segments_into_chapters(transcript.segments)
        
        for i, (start_time, title) in enumerate(chapter_groups):
            timestamp = self._seconds_to_timestamp(start_time)
            chapters.append(f"{timestamp} {title}")
        
        return chapters
    
    def _group_segments_into_chapters(self, segments: List[TranscriptSegment]) -> List[tuple]:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        
        Args:
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§
            
        Returns:
            List[tuple]: (é–‹å§‹æ™‚é–“, ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã‚¿ã‚¤ãƒˆãƒ«) ã®ãƒªã‚¹ãƒˆ
        """
        if not segments:
            return []
        
        chapters = [(0.0, "ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³")]
        
        # è©±è€…å¤‰æ›´ã‚„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå¤‰æ›´ã§ãƒãƒ£ãƒ—ã‚¿ãƒ¼åˆ†å‰²
        current_chapter_start = segments[0].start_time
        current_speaker = segments[0].speaker
        current_key_points = set(segments[0].key_points)
        
        for i, segment in enumerate(segments[1:], 1):
            # ãƒãƒ£ãƒ—ã‚¿ãƒ¼åˆ†å‰²æ¡ä»¶
            should_split = (
                segment.speaker != current_speaker or
                len(set(segment.key_points).intersection(current_key_points)) < 1 or
                segment.start_time - current_chapter_start > 120  # 2åˆ†ä»¥ä¸Š
            )
            
            if should_split and i < len(segments) - 1:  # æœ€å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯é™¤ã
                # ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
                title = self._generate_chapter_title(segments[i-3:i+1])
                chapters.append((segment.start_time, title))
                
                current_chapter_start = segment.start_time
                current_speaker = segment.speaker
                current_key_points = set(segment.key_points)
        
        return chapters[:10]  # æœ€å¤§10ãƒãƒ£ãƒ—ã‚¿ãƒ¼
    
    def _generate_chapter_title(self, segments: List[TranscriptSegment]) -> str:
        """
        ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            segments: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¸€è¦§
            
        Returns:
            str: ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã‚¿ã‚¤ãƒˆãƒ«
        """
        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æœ€é »å‡ºã®ã‚‚ã®ã‚’é¸æŠ
        all_points = []
        for seg in segments:
            all_points.extend(seg.key_points)
        
        if all_points:
            point_counts = Counter(all_points)
            most_common = point_counts.most_common(1)[0][0]
            return f"{most_common}ã«ã¤ã„ã¦"
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰
        if segments:
            first_text = segments[0].text
            return first_text[:20] + "..." if len(first_text) > 20 else first_text
        
        return "è©³ç´°è§£èª¬"
    
    def _extract_key_points_for_description(self, transcript: TranscriptInfo) -> List[str]:
        """
        æ¦‚è¦æ¬„ç”¨ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: é‡è¦ãƒã‚¤ãƒ³ãƒˆä¸€è¦§
        """
        all_key_points = []
        for segment in transcript.segments:
            all_key_points.extend(segment.key_points)
        
        # é »å‡ºåº¦ã§ã‚½ãƒ¼ãƒˆ
        point_counts = Counter(all_key_points)
        top_points = [point for point, count in point_counts.most_common(5)]
        
        return top_points
    
    def _extract_source_information(self, transcript: TranscriptInfo) -> List[str]:
        """
        ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’æŠ½å‡º
        
        å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰URLã€å¼•ç”¨ã€å‚ç…§æƒ…å ±ã‚’æŠ½å‡º
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ã‚½ãƒ¼ã‚¹æƒ…å ±ä¸€è¦§
        """
        import re
        
        sources = []
        seen_urls = set()
        
        # å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
        full_text = " ".join(seg.text for seg in transcript.segments)
        
        # 1. URLæŠ½å‡º
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        urls = re.findall(url_pattern, full_text)
        for url in urls:
            # URLã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæœ«å°¾ã®å¥èª­ç‚¹é™¤å»ï¼‰
            url = url.rstrip('.,;:!?ï¼‰ã€ã€ã€‘')
            if url not in seen_urls:
                seen_urls.add(url)
                sources.append(f"ğŸ”— {url}")
        
        # 2. å¼•ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡ºï¼ˆã€Œã€œã«ã‚ˆã‚‹ã¨ã€ã€Œã€œã®èª¿æŸ»ã€ç­‰ï¼‰
        quote_patterns = [
            r'ã€Œ([^ã€]+)ã€ã«ã‚ˆã‚‹ã¨',
            r'ã€Œ([^ã€]+)ã€ã®(èª¿æŸ»|å ±å‘Š|ç™ºè¡¨|ç ”ç©¶)',
            r'([A-Za-z0-9]+(?:ç¤¾|ç ”ç©¶æ‰€|å¤§å­¦|æ©Ÿé–¢))ã®',
            r'([\u4e00-\u9fff]+(?:çœ|åº|å§”å“¡ä¼š))(?:ãŒ|ã®|ã¯)',
        ]
        
        for pattern in quote_patterns:
            matches = re.findall(pattern, full_text)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0]
                if match and len(match) >= 2 and match not in seen_urls:
                    seen_urls.add(match)
                    sources.append(f"ğŸ“– {match}")
        
        # 3. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å‚ç…§æƒ…å ±ã‚’æŠ½å‡º
        for segment in transcript.segments:
            for point in segment.key_points:
                # ã€Œã€œã«åŸºã¥ãã€ã€Œã€œã‚’å‚ç…§ã€ç­‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                if any(kw in point for kw in ["å‚ç…§", "å¼•ç”¨", "å‡ºå…¸", "ã‚½ãƒ¼ã‚¹", "ãƒ‡ãƒ¼ã‚¿"]):
                    if point not in seen_urls:
                        seen_urls.add(point)
                        sources.append(f"ğŸ“Š {point}")
        
        # 4. ã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        if not sources:
            sources = [
                "â€» æœ¬å‹•ç”»ã®æƒ…å ±ã¯ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ã„ã¾ã™",
                "â€» æœ€æ–°æƒ…å ±ã«ã¤ã„ã¦ã¯å…¬å¼ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„"
            ]
        else:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
            sources.insert(0, "ã€å‚è€ƒæƒ…å ±ãƒ»å¼•ç”¨å…ƒã€‘")
            sources.append("")
            sources.append("â€» æƒ…å ±ã¯å‹•ç”»ä½œæˆæ™‚ç‚¹ã®ã‚‚ã®ã§ã™")
        
        return sources[:10]  # æœ€å¤§10ä»¶
    
    def _generate_tags(self, transcript: TranscriptInfo) -> List[str]:
        """
        å‹•ç”»ã‚¿ã‚°ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ã‚¿ã‚°ä¸€è¦§
        """
        tags = []
        
        # 1. ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã‚¿ã‚°ç”Ÿæˆ
        all_key_points = []
        for segment in transcript.segments:
            all_key_points.extend(segment.key_points)
        
        point_counts = Counter(all_key_points)
        for point, count in point_counts.most_common(10):
            if len(point) <= 30:  # ã‚¿ã‚°ã®é•·ã•åˆ¶é™
                tags.append(point)
        
        # 2. ä¸€èˆ¬çš„ãªè§£èª¬å‹•ç”»ã‚¿ã‚°
        general_tags = [
            "è§£èª¬å‹•ç”»",
            "ã‚ã‹ã‚Šã‚„ã™ã„",
            "åˆå¿ƒè€…å‘ã‘",
            "å­¦ç¿’",
            "æ•™è‚²",
            "æ—¥æœ¬èª"
        ]
        tags.extend(general_tags)
        
        # 3. ãƒˆãƒ”ãƒƒã‚¯é–¢é€£ã‚¿ã‚°
        topic_tags = self._generate_topic_tags(transcript)
        tags.extend(topic_tags)
        
        # é‡è¤‡é™¤å»ã¨æ–‡å­—æ•°åˆ¶é™
        unique_tags = list(dict.fromkeys(tags))  # é †åºä¿æŒã§é‡è¤‡é™¤å»
        
        # æ–‡å­—æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        total_length = sum(len(tag) for tag in unique_tags) + len(unique_tags) - 1  # ã‚«ãƒ³ãƒåˆ†
        if total_length > self.max_tags_length:
            # æ–‡å­—æ•°åˆ¶é™å†…ã«åã¾ã‚‹ã‚ˆã†èª¿æ•´
            adjusted_tags = []
            current_length = 0
            
            for tag in unique_tags:
                if current_length + len(tag) + 1 <= self.max_tags_length:
                    adjusted_tags.append(tag)
                    current_length += len(tag) + 1
                else:
                    break
            
            return adjusted_tags
        
        return unique_tags[:15]  # æœ€å¤§15ã‚¿ã‚°
    
    def _generate_topic_tags(self, transcript: TranscriptInfo) -> List[str]:
        """
        ãƒˆãƒ”ãƒƒã‚¯é–¢é€£ã®ã‚¿ã‚°ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ãƒˆãƒ”ãƒƒã‚¯é–¢é€£ã‚¿ã‚°
        """
        topic_tags = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰æŠ€è¡“ç”¨èªã‚’æŠ½å‡º
        full_text = " ".join(segment.text for segment in transcript.segments)
        
        # æŠ€è¡“ç”¨èªãƒ‘ã‚¿ãƒ¼ãƒ³
        tech_patterns = [
            r'AI|äººå·¥çŸ¥èƒ½|æ©Ÿæ¢°å­¦ç¿’|æ·±å±¤å­¦ç¿’|ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°',
            r'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°|ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°|é–‹ç™º',
            r'ãƒ‡ãƒ¼ã‚¿|ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ |ã‚·ã‚¹ãƒ†ãƒ ',
            r'ã‚¯ãƒ©ã‚¦ãƒ‰|ã‚µãƒ¼ãƒãƒ¼|ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯',
            r'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£|æš—å·åŒ–|èªè¨¼'
        ]
        
        for pattern in tech_patterns:
            matches = re.findall(pattern, full_text, re.IGNORECASE)
            topic_tags.extend(matches)
        
        # é‡è¤‡é™¤å»
        return list(set(topic_tags))
    
    def _generate_thumbnail_suggestions(self, transcript: TranscriptInfo) -> List[str]:
        """
        ã‚µãƒ ãƒã‚¤ãƒ«ææ¡ˆã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ã‚µãƒ ãƒã‚¤ãƒ«ææ¡ˆä¸€è¦§
        """
        suggestions = []
        
        # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ææ¡ˆ
        keywords = self._extract_main_keywords(transcript)
        for keyword in keywords[:3]:
            suggestions.append(f"{keyword}ã®å›³è§£ã‚¤ãƒ¡ãƒ¼ã‚¸")
            suggestions.append(f"{keyword}ã‚’ãƒ†ãƒ¼ãƒã«ã—ãŸã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯")
        
        # ä¸€èˆ¬çš„ãªè§£èª¬å‹•ç”»ã‚µãƒ ãƒã‚¤ãƒ«ææ¡ˆ
        suggestions.extend([
            "ç–‘å•ç¬¦(?)ã¨é›»çƒã®ã‚¢ã‚¤ã‚³ãƒ³",
            "ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®å›³è§£",
            "ãƒ“ãƒ•ã‚©ãƒ¼ãƒ»ã‚¢ãƒ•ã‚¿ãƒ¼ã®æ¯”è¼ƒç”»åƒ",
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆã‚’å¼·èª¿ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç”»åƒ"
        ])
        
        return suggestions
    
    def _extract_main_keywords(self, transcript: TranscriptInfo) -> List[str]:
        """
        ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            List[str]: ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§
        """
        all_key_points = []
        for segment in transcript.segments:
            all_key_points.extend(segment.key_points)
        
        point_counts = Counter(all_key_points)
        return [point for point, count in point_counts.most_common(5)]
    
    def _get_main_hashtag(self, transcript: TranscriptInfo) -> str:
        """
        ãƒ¡ã‚¤ãƒ³ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å–å¾—
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            
        Returns:
            str: ãƒ¡ã‚¤ãƒ³ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
        """
        keywords = self._extract_main_keywords(transcript)
        if keywords:
            return keywords[0].replace(' ', '')
        return "è§£èª¬"
    
    def _seconds_to_timestamp(self, seconds: float) -> str:
        """
        ç§’ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ›
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            str: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— (MM:SS)
        """
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"
    
    def _create_shortened_description(
        self, 
        transcript: TranscriptInfo, 
        summary: str, 
        chapters: List[str]
    ) -> str:
        """
        çŸ­ç¸®ç‰ˆæ¦‚è¦æ¬„ã‚’ä½œæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            summary: è¦ç´„
            chapters: ãƒãƒ£ãƒ—ã‚¿ãƒ¼ä¸€è¦§
            
        Returns:
            str: çŸ­ç¸®ç‰ˆæ¦‚è¦æ¬„
        """
        parts = [
            f"ã€å‹•ç”»æ¦‚è¦ã€‘\n{summary}\n",
            "ã€ç›®æ¬¡ã€‘"
        ]
        parts.extend(chapters)
        parts.extend([
            "",
            "ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ãƒ»é«˜è©•ä¾¡ã‚’ãŠé¡˜ã„ã—ã¾ã™ï¼",
            f"#{self._get_main_hashtag(transcript)} #è§£èª¬å‹•ç”»"
        ])
        
        return "\n".join(parts)
    
    def optimize_for_seo(self, metadata: Dict[str, Any], target_keywords: List[str]) -> Dict[str, Any]:
        """
        SEOæœ€é©åŒ–
        
        Args:
            metadata: å…ƒã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            target_keywords: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            
        Returns:
            Dict[str, Any]: SEOæœ€é©åŒ–æ¸ˆã¿ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        optimized = metadata.copy()
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
        if target_keywords and target_keywords[0] not in optimized["title"]:
            new_title = f"{target_keywords[0]} - {optimized['title']}"
            if len(new_title) <= self.max_title_length:
                optimized["title"] = new_title
        
        # æ¦‚è¦æ¬„ã®æœ€åˆã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é…ç½®
        if target_keywords:
            keyword_line = f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(target_keywords[:3])}\n\n"
            optimized["description"] = keyword_line + optimized["description"]
        
        return optimized

    def _generate_title_from_template(self, transcript: TranscriptInfo, template: Dict[str, Any]) -> str:
        """
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
        """
        title_template = template.get('title_template', '{topic} - {key_points}')
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è§£æ±º
        replacements = {
            '{topic}': transcript.title or 'ãƒˆãƒ”ãƒƒã‚¯ãªã—',
            '{key_points}': self._get_key_points_string(transcript),
            '{duration}': self._format_duration(transcript),
        }
        
        title = title_template
        for placeholder, value in replacements.items():
            title = title.replace(placeholder, value)
        
        # é•·ã•åˆ¶é™
        if len(title) > self.max_title_length:
            title = title[:self.max_title_length-3] + "..."
        
        return title

    def _generate_description_from_template(self, transcript: TranscriptInfo, template: Dict[str, Any]) -> str:
        """
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰æ¦‚è¦æ¬„ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸæ¦‚è¦æ¬„
        """
        desc_template = template.get('description_template', 'ã“ã®å‹•ç”»ã§ã¯{topic}ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚\n\n{toc}\n\n{hashtags}')
        
        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è§£æ±º
        replacements = {
            '{topic}': transcript.title or 'ãƒˆãƒ”ãƒƒã‚¯ãªã—',
            '{toc}': self._generate_toc_string(transcript),
            '{hashtags}': self._generate_hashtags_string(transcript),
            '{summary}': self._generate_video_summary(transcript),
        }
        
        description = desc_template
        for placeholder, value in replacements.items():
            description = description.replace(placeholder, value)
        
        # é•·ã•åˆ¶é™
        if len(description) > self.max_description_length:
            description = description[:self.max_description_length-3] + "..."
        
        return description

    def _generate_tags_from_template(self, transcript: TranscriptInfo, template: Dict[str, Any]) -> List[str]:
        """
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ã‚¿ã‚°ã‚’ç”Ÿæˆ
        
        Args:
            transcript: å°æœ¬æƒ…å ±
            template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
            
        Returns:
            List[str]: ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚°
        """
        tags_template = template.get('tags_template', ['{topic}', 'è§£èª¬', 'ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«'])
        
        tags = []
        for tag_template in tags_template:
            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è§£æ±º
            tag = tag_template.replace('{topic}', transcript.title or 'ãƒˆãƒ”ãƒƒã‚¯ãªã—')
            tags.append(tag)
        
        # æ–‡å­—æ•°åˆ¶é™
        total_length = sum(len(tag) for tag in tags) + len(tags) - 1
        if total_length > self.max_tags_length:
            # çŸ­ãã™ã‚‹
            tags = tags[:10]  # æœ€å¤§10ã‚¿ã‚°
        
        return tags

    def _get_key_points_string(self, transcript: TranscriptInfo) -> str:
        """ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æ–‡å­—åˆ—åŒ–"""
        keywords = self._extract_main_keywords(transcript)
        return ', '.join(keywords[:3])

    def _format_duration(self, transcript: TranscriptInfo) -> str:
        """å‹•ç”»æ™‚é–“ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if transcript.segments:
            total_time = max(seg.end_time for seg in transcript.segments)
            minutes = int(total_time // 60)
            return f"{minutes}åˆ†"
        return "ä¸æ˜"

    def _generate_toc_string(self, transcript: TranscriptInfo) -> str:
        """ç›®æ¬¡ã‚’æ–‡å­—åˆ—åŒ–"""
        chapters = self._generate_chapters(transcript)
        return '\n'.join(chapters[:5])  # æœ€å¤§5ãƒãƒ£ãƒ—ã‚¿ãƒ¼

    def _generate_hashtags_string(self, transcript: TranscriptInfo) -> str:
        """ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’æ–‡å­—åˆ—åŒ–"""
        hashtags = [f"#{tag.replace(' ', '')}" for tag in self._extract_main_keywords(transcript)[:3]]
        return ' '.join(hashtags)

    def create_template_from_metadata(self, metadata: Dict[str, Any], template_name: str) -> None:
        """
        æ—¢å­˜ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        
        Args:
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
        """
        template = {
            'title_template': metadata.get('title', '{topic} - {key_points}'),
            'description_template': metadata.get('description', 'ã“ã®å‹•ç”»ã§ã¯{topic}ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚\n\n{toc}\n\n{hashtags}'),
            'tags_template': metadata.get('tags', ['{topic}', 'è§£èª¬']),
            'category_id': metadata.get('category_id', self.youtube_settings['category_id']),
            'language': metadata.get('language', self.youtube_settings['default_language'])
        }
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¿å­˜
        template_path = self.template_dir / f"{template_name}.json"
        with open(template_path, 'w', encoding='utf-8') as f:
            json.dump(template, f, ensure_ascii=False, indent=2)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
        self.templates[template_name] = template
        logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_name}' ã‚’ä½œæˆã—ã¾ã—ãŸ")

    def edit_template(self, template_name: str, updates: Dict[str, Any]) -> None:
        """
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç·¨é›†
        
        Args:
            template_name: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå
            updates: æ›´æ–°å†…å®¹
        """
        if template_name not in self.templates:
            raise ValueError(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # æ›´æ–°é©ç”¨
        self.templates[template_name].update(updates)
        
        # ä¿å­˜
        template_path = self.template_dir / f"{template_name}.json"
        with open(template_path, 'w', encoding='utf-8') as f:
            json.dump(self.templates[template_name], f, ensure_ascii=False, indent=2)
        
        logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ '{template_name}' ã‚’æ›´æ–°ã—ã¾ã—ãŸ")

    def list_templates(self) -> Dict[str, Dict[str, Any]]:
        """
        åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—
        
        Returns:
            Dict[str, Dict[str, Any]]: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§
        """
        return self.templates.copy()
